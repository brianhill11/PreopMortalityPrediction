{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
      "/Users/bhizzle/codepy:/Users/bhizzle/cgen:/usr/local:/Users/bhizzle/usr/local:/usr/local/caffe2/python:\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fancyimpute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-681ee997a71b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfancyimpute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSoftImpute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mehr_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fancyimpute'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "print(sys.version_info)\n",
    "\n",
    "home_dir = os.getenv(\"HOME\")\n",
    "print(os.getenv(\"PYTHONPATH\"))\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, LabelEncoder\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, brier_score_loss, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet, ElasticNetCV, ARDRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from fancyimpute import SoftImpute\n",
    "from ehr_utils import *\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False to hide IDs    \n",
    "verbose = False\n",
    "\n",
    "## this variable is the column that we will use as the target variable for the model\n",
    "TARGET_VARIABLE = 'INPT_DEATH_YN'\n",
    "\n",
    "MIN_ASA_STATUS=1\n",
    "MAX_ASA_STATUS=5\n",
    "MIN_AGE=18\n",
    "MAX_AGE=89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data into dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_filtered_f = \"main_Nov21_2017_Feb_13_2018.filtered.main.txt\"\n",
    "\n",
    "exp_prefix = \"preop_asa\"\n",
    "dir_to_save_files = os.path.join(\"paper/\", exp_prefix)\n",
    "\n",
    "if not os.path.exists(dir_to_save_files):\n",
    "    os.makedirs(dir_to_save_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(df.shape)? (<ipython-input-38-1a42f2af2ea1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-1a42f2af2ea1>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print df.shape\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(df.shape)?\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(main_filtered_f,sep=\"|\")\n",
    "print df.shape\n",
    "print len(df.columns)\n",
    "if verbose:\n",
    "    display(df.iloc[0:20, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop any rows that are exact copies of another row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(df.shape)? (<ipython-input-39-580e934a7e09>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-580e934a7e09>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print df.shape\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(df.shape)?\n"
     ]
    }
   ],
   "source": [
    "print df.shape\n",
    "df.drop_duplicates(inplace=True)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in features file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dir_to_save_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-45f32f6a3ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFEATURES_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_to_save_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EHR_MAIN_FEATURES.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfeatures_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFEATURES_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatures_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dir_to_save_files' is not defined"
     ]
    }
   ],
   "source": [
    "FEATURES_PATH = os.path.join(dir_to_save_files, 'EHR_MAIN_FEATURES.csv')\n",
    "features_df = pd.read_csv(FEATURES_PATH)\n",
    "\n",
    "features_dict = {name:list(col.dropna()) for name,col in features_df.items()}\n",
    "print(features_dict.keys())\n",
    "\n",
    "final_features = features_dict['final_features']\n",
    "cat_to_drop = features_dict['cat_to_drop']\n",
    "outcome_vars = features_dict['outcome_vars']\n",
    "feat_to_drop = features_dict['feat_to_drop']\n",
    "cat_vars = features_dict['cat_vars']\n",
    "contin_vars = features_dict['contin_vars']\n",
    "bool_outcome_vars = features_dict['bool_outcome_vars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out surgeries that don't occur in RR or SM operating rooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-929a35ab8ef4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLOCATION_GROUP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#df = df[df['LOCATION_GROUP'].isin(['RR OR', 'SM OR','SM SC','SM OB OR','RR OB OR'])]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LOCATION_GROUP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RR OR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SM OR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SM SC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "print(df.LOCATION_GROUP.unique())\n",
    "#df = df[df['LOCATION_GROUP'].isin(['RR OR', 'SM OR','SM SC','SM OB OR','RR OB OR'])]\n",
    "print(df.shape)\n",
    "df = df[df['LOCATION_GROUP'].isin(['RR OR', 'SM OR', 'SM SC'])]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out surgeries that were not INPATIENT, SAME DAY ADMIT, EMERGENCY, or OVERNIGHT RECOVERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"Shape before filtering out outpatient surgeries:\", df.shape)? (<ipython-input-42-22291916d42d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-22291916d42d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print \"Shape before filtering out outpatient surgeries:\", df.shape\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"Shape before filtering out outpatient surgeries:\", df.shape)?\n"
     ]
    }
   ],
   "source": [
    "print \"Shape before filtering out outpatient surgeries:\", df.shape\n",
    "#df = df[df['PATIENT_CLASS'].isin(['INPATIENT', 'SAME DAY ADMIT', 'EMERGENCY', 'OVERNIGHT RECOVERY'])]\n",
    "df = df[df['PAT_CLASS'].isin(['INPATIENT', 'SAME DAY ADMIT', 'EMERGENCY', 'OVERNIGHT RECOVERY'])]\n",
    "print \"Shape after filtering out outpatient surgeries:\", df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter based on ASA status, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"Shape before filtering out based on ASA_STATUS:\", df.shape)? (<ipython-input-43-9508c88373ba>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-9508c88373ba>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print \"Shape before filtering out based on ASA_STATUS:\", df.shape\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"Shape before filtering out based on ASA_STATUS:\", df.shape)?\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print \"Shape before filtering out based on ASA_STATUS:\", df.shape\n",
    "    print \"ASA_STATUS mean:\", df.ASA_STATUS.mean()\n",
    "    df = df[(df[\"ASA_STATUS\"] <= MAX_ASA_STATUS) & (df[\"ASA_STATUS\"] >= MIN_ASA_STATUS)]\n",
    "    print \"Shape after filtering out based on ASA_STATUS:\", df.shape\n",
    "    print \"ASA_STATUS mean:\", df.ASA_STATUS.mean()\n",
    "except AttributeError:\n",
    "    pass\n",
    "print \"===================================\"\n",
    "print \"Mean age:\", df.AGE_LT_90.mean()\n",
    "print \"STD age:\", df.AGE_LT_90.std()\n",
    "df = df[(df[\"AGE_LT_90\"] <= MAX_AGE) & (df[\"AGE_LT_90\"] >= MIN_AGE)]\n",
    "print \"Mean age:\", df.AGE_LT_90.mean()\n",
    "print \"STD age:\", df.AGE_LT_90.std()\n",
    "print \"Shape after filtering out based on AGE_LT_90:\", df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check demographic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"Number of Patients:\", df.shape[0])? (<ipython-input-44-7a9b31f35a0d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-7a9b31f35a0d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print \"Number of Patients:\", df.shape[0]\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"Number of Patients:\", df.shape[0])?\n"
     ]
    }
   ],
   "source": [
    "print \"Number of Patients:\", df.shape[0]\n",
    "print \"Patients with in-hospital mortality: {} ({}%)\".format(df.INPT_DEATH_YN.value_counts()[1], df.INPT_DEATH_YN.value_counts(normalize=\"True\")[1]*100)\n",
    "print \"Patients with kidney failure: {} ({}%)\".format(df.AKIN_EVENT.value_counts()[1], df.AKIN_EVENT.value_counts(normalize=\"True\")[1]*100)\n",
    "print \"Mean age:\", df.AGE_LT_90.mean(), \" std:\", df.AGE_LT_90.std()\n",
    "print \"Number of female patients: {} ({}%)\".format(df[df[\"GENDER\"] == \"F\"].shape[0], df[df[\"GENDER\"] == \"F\"].shape[0]/float(df.shape[0])*100)\n",
    "\n",
    "try:\n",
    "    print \"Number of patients in RR OR: {} ({}%)\".format(df.LOCATION_GROUP.value_counts()[\"RR OR\"], df.LOCATION_GROUP.value_counts(normalize=\"True\")[\"RR OR\"]*100)\n",
    "    print \"Number of patients in SM OR: {} ({}%)\".format(df.LOCATION_GROUP.value_counts()[\"SM OR\"], df.LOCATION_GROUP.value_counts(normalize=\"True\")[\"SM OR\"]*100)\n",
    "    print \"Number of patients in SM SC: {} ({}%)\".format(df.LOCATION_GROUP.value_counts()[\"SM SC\"], df.LOCATION_GROUP.value_counts(normalize=\"True\")[\"SM SC\"]*100)\n",
    "except AttributeError:\n",
    "    pass\n",
    "print(\"=\"*40)\n",
    "try:\n",
    "    print \"ASA Status:\", df.ASA_STATUS.value_counts()\n",
    "    print \"ASA Status (%):\", (df.ASA_STATUS.value_counts()/df.shape[0])*100\n",
    "except AttributeError:\n",
    "    pass\n",
    "\n",
    "print(\"=\"*40)\n",
    "print \"Mean age of mortalities:\", df[df[\"INPT_DEATH_YN\"] == 1].AGE_LT_90.mean(), \" std:\", df[df[\"INPT_DEATH_YN\"] == 1].AGE_LT_90.std()\n",
    "print(\"Number of female mortalities: {} ({}%)\".format(df[df[\"GENDER\"] == \"F\"][\"INPT_DEATH_YN\"].sum(), \n",
    "                                                     df[df[\"GENDER\"] == \"F\"][\"INPT_DEATH_YN\"].sum()/float(df[\"INPT_DEATH_YN\"].sum())*100))\n",
    "print(\"Number of male mortalities: {} ({}%)\".format(df[df[\"GENDER\"] == \"M\"][\"INPT_DEATH_YN\"].sum(), \n",
    "                                                     df[df[\"GENDER\"] == \"M\"][\"INPT_DEATH_YN\"].sum()/float(df[\"INPT_DEATH_YN\"].sum())*100))\n",
    "try:\n",
    "    print(\"=\"*40)\n",
    "    print(\"Number of mortalities stratified by location\")\n",
    "    print(df.groupby(\"LOCATION_GROUP\")[\"INPT_DEATH_YN\"].sum())                                \n",
    "    print(df.groupby(\"LOCATION_GROUP\")[\"INPT_DEATH_YN\"].sum()/float(df[\"INPT_DEATH_YN\"].sum())*100)\n",
    "except AttributeError:\n",
    "    pass\n",
    "print(\"=\"*40)\n",
    "print(\"Number of mortalities stratified by ASA status\")\n",
    "print(df.groupby(\"ASA_STATUS\")[\"INPT_DEATH_YN\"].sum())\n",
    "print(df.groupby(\"ASA_STATUS\")[\"INPT_DEATH_YN\"].sum()/float(df[\"INPT_DEATH_YN\"].sum())*100)\n",
    "\n",
    "if verbose:\n",
    "    print(df[\"CASE_SRV_NAME\"].value_counts())\n",
    "    print(df[\"CASE_SRV_NAME\"].value_counts()/df.shape[0])*100\n",
    "    print(\"=\"*40)\n",
    "    print(df[df[\"INPT_DEATH_YN\"] == 1][\"CASE_SRV_NAME\"].value_counts())\n",
    "    print(df[df[\"INPT_DEATH_YN\"] == 1][\"CASE_SRV_NAME\"].value_counts()/df[\"INPT_DEATH_YN\"].sum())*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove outlier values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(df_string_cols.columns.values)? (<ipython-input-45-6a0f0d2cd52b>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-45-6a0f0d2cd52b>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print df_string_cols.columns.values\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(df_string_cols.columns.values)?\n"
     ]
    }
   ],
   "source": [
    "string_cols = ['PRE_SURG_LOCATION', 'CASE_SRV_NAME_GROUP', 'CASE_SRV_NAME', 'PRIMARY_CPT',\n",
    "                                  'GENDER', 'HCUP_DESC', 'CPT_DESC', 'PAT_CLASS', 'OR_CASE_ID', 'ADMSN_ID']\n",
    "dff = df.drop(['PRE_SURG_LOCATION', 'CASE_SRV_NAME_GROUP', 'CASE_SRV_NAME', 'PRIMARY_CPT',\n",
    "                                  'GENDER', 'HCUP_DESC', 'CPT_DESC', 'PAT_CLASS', 'OR_CASE_ID', 'ADMSN_ID'], axis=1)\n",
    "dff = df.select_dtypes(include=['float64'])\n",
    "df_string_cols = df[df.columns.difference(dff.columns.values)]\n",
    "print df_string_cols.columns.values\n",
    "#display(dff.describe())\n",
    "print (np.abs(st.zscore(dff, axis=1)) > 3)\n",
    "#print dff.sub(dff.mean()).div(dff.std()).abs().lt(3)\n",
    "df_no_outliers = dff[dff.sub(dff.mean()).div(dff.std()).abs().lt(4)]\n",
    "df_no_outliers[df_string_cols.columns.values] = df_string_cols\n",
    "if verbose:\n",
    "    display(df_no_outliers.describe(include=\"all\"))\n",
    "df = df_no_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove variables related to lab times (i.e. *.HRS_2_SURGERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove variables that have to do with time\n",
    "# cols_to_keep_no_hrs2surgery = [c for c in df.columns if not c.endswith(\".HRS_2_SURGERY\")]\n",
    "# print cols_to_keep_no_hrs2surgery\n",
    "# print len(cols_to_keep_no_hrs2surgery)\n",
    "# df=df[cols_to_keep_no_hrs2surgery]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unnecessary features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(admsn_surgery_number.shape)? (<ipython-input-47-9e38ddde2288>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-9e38ddde2288>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print admsn_surgery_number.shape\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(admsn_surgery_number.shape)?\n"
     ]
    }
   ],
   "source": [
    "# save this for checking predictions over time\n",
    "admsn_surgery_number = df[\"ADMSN_SURGERY_NUMBER\"]\n",
    "print admsn_surgery_number.shape\n",
    "or_case_id_number = df[\"OR_CASE_ID\"]\n",
    "admsn_ids = df['ADMSN_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[final_features + [TARGET_VARIABLE]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in cat_vars:\n",
    "    try:\n",
    "        # drop_first uses k-1 dummies out of k categories\n",
    "        print var\n",
    "        df = pd.get_dummies(df, columns=[var], drop_first=True)\n",
    "        pass\n",
    "    except ValueError:\n",
    "        pass\n",
    "# remove categorical variables (string values)\n",
    "for var in cat_vars:\n",
    "    try:\n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        pass\n",
    "    except ValueError:\n",
    "        print var, 'already dropped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove features we don't want to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(feature_whitelist) == 0:\n",
    "    for cat in cat_to_drop:\n",
    "        try:\n",
    "            df.drop(cat, axis=1, inplace=True)\n",
    "        except ValueError:\n",
    "            print cat, 'already dropped'\n",
    "#print df.columns.values\n",
    "for col in sorted(df.columns.values):\n",
    "    print col, \"\\t\\t\", df[col].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove target variables from data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Column names:\", df.columns.values\n",
    "try:\n",
    "    y = np.ravel(df[TARGET_VARIABLE])\n",
    "    #asa_status = df[\"ASA_STATUS\"]\n",
    "    df.drop(TARGET_VARIABLE, axis=1, inplace=True, errors='ignore')\n",
    "    df.drop(outcome_vars, axis=1, inplace=True, errors='ignore')\n",
    "    input_death_yn = df['INPT_DEATH_YN']\n",
    "except KeyError:\n",
    "    print TARGET_VARIABLE, \"already dropped\"\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html\n",
    "# default stragegy: mean\n",
    "# if len(feature_whitelist) > 0:\n",
    "#     feature_whitelist = [c for c in feature_whitelist if not c.endswith(\".HRS_2_SURGERY\")]\n",
    "#     df = df[feature_whitelist]\n",
    "print df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize training, testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardizeWithNaN(TransformerMixin, BaseEstimator):\n",
    "    '''This estimator is for standardizing a dataset that has missing data'''\n",
    "    def __init__(self):\n",
    "        self.X_mean = []\n",
    "        self.X_std = []\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # get mean and standard deviation of columns\n",
    "        self.X_mean = np.nanmean(X, axis=0)\n",
    "        self.X_std  = np.nanstd(X, axis=0) \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # subtract mean and divide by standard deviation\n",
    "        return (X - self.X_mean)/self.X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardizeWithNaN()\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftImputeEstimator(TransformerMixin, BaseEstimator):\n",
    "    '''This estimator is for wrapping the SoftImpute algorithm'''\n",
    "    def __init__(self, max_iters=200, verbose=True):\n",
    "        self.max_iters = max_iters\n",
    "        self.verbose = verbose\n",
    "        self.fit_count = 0\n",
    "        self.transform_count = 0\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.fit_count += 1\n",
    "        print(\"SoftImputeEstimator fit count: {}\".format(self.fit_count))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.transform_count += 1\n",
    "        print(\"SoftImputeEstimator transform count: {}\".format(self.transform_count))\n",
    "        try:\n",
    "            # subtract mean and divide by standard deviation\n",
    "            return SoftImpute(max_iters=self.max_iters, verbose=self.verbose).complete(X.replace(np.inf, np.nan))\n",
    "        # ValueError raised if no values need to be imputed\n",
    "        except ValueError:\n",
    "            return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputing X_test\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'si' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-f637a1cb68b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imputing X_test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(np.isnan(X_test).any())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'si' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"imputing X_test\")\n",
    "#print(np.isnan(X_test).any())\n",
    "X_test = si.transform(X_test.replace(np.inf, np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict classes and get probability of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-49-5af6e5cb60d8>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-49-5af6e5cb60d8>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    model_probs = model.predict_proba(X_test)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model_predictions = model.predict(np.array(X_test)\n",
    "model_probs = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If we have true labels, see how well the model did "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_accuracy_roc_auc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-f8c781d3f175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_accuracy_roc_auc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"accuracy_roc_auc.tif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_accuracy_roc_auc' is not defined"
     ]
    }
   ],
   "source": [
    "plot_accuracy_roc_auc(models, model_names, model_predictions, model_probs, y_train, y_test, \"accuracy_roc_auc.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(models, model_names, model_probs, y_test, os.path.join(dir_to_save_files,\"roc_curve.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(models, model_names, model_probs, y_test, os.path.join(dir_to_save_files, \"precision_recall_curve.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sc]",
   "language": "python",
   "name": "conda-env-sc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
